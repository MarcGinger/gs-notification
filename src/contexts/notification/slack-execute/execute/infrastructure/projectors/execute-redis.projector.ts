// @generated by gen v1.0.0 hash:regen
// REMOVE THIS COMMENT TO STOP AUTOMATIC UPDATES TO THIS BLOCK

// Execute Projector - ESDB to Redis Projection
// Refactored to use shared projection infrastructure with Redis backend

import {
  Injectable,
  Inject,
  OnModuleInit,
  OnModuleDestroy,
} from '@nestjs/common';
import Redis from 'ioredis';
import {
  CatchUpRunner,
  ProjectionEvent,
  RunOptions,
} from 'src/shared/infrastructure/projections/catchup.runner';
import { CheckpointStore } from 'src/shared/infrastructure/projections/checkpoint.store';
import { BaseProjector } from 'src/shared/infrastructure/projections/base.projector';
import {
  CommonProjectorErrorDefinitions,
  createProjectorErrorCatalog,
  TenantExtractor,
} from 'src/shared/infrastructure/projections/projection.utils';
// ✅ Import executeion-ready shared utilities
import { registerRedisScripts } from 'src/shared/infrastructure/projections/redis-scripts';
import {
  CacheOptimizationUtils,
  CacheMetricsCollector,
} from 'src/shared/infrastructure/projections/cache-optimization';
import { RedisPipelineBuilder } from 'src/shared/infrastructure/projections/redis-pipeline-builder';
import { RedisClusterUtils } from 'src/shared/infrastructure/projections/redis-scripts';
import { ProjectionOutcome } from 'src/shared/infrastructure/projections/event-pipeline-processor';
import { CHECKPOINT_STORE } from 'src/shared/constants/injection-tokens';
import { APP_LOGGER, Log, Logger } from 'src/shared/logging';
import { Clock, CLOCK } from 'src/shared/infrastructure/time';
import { withContext } from 'src/shared/errors';
import { CacheService } from 'src/shared/application/caching/cache.service';
import { SLACK_EXECUTE_DI_TOKENS } from '../../../slack-execute.constants';

import { ExecuteProjectionKeys } from '../../execute-projection-keys';
import { ExecuteFieldValidatorUtil } from '../utilities/execute-field-validator.util';
import { DetailExecuteResponse } from '../../application/dtos';

/**
 * Execute projector error catalog using shared error definitions
 */
const ExecuteProjectorErrors = createProjectorErrorCatalog(
  'EXECUTE_PROJECTOR',
  CommonProjectorErrorDefinitions,
);

/**
 * Execute row parameters for Redis projection operations
 *
 * Extends DetailExecuteResponse DTO with projection-specific fields needed for event sourcing.
 *
 * Key Additions to DetailExecuteResponse:
 * - tenantId: Multi-tenant support for Redis key generation
 * - deletedAt: Soft delete timestamp for TTL-based cleanup
 * - lastStreamRevision: Event sourcing revision tracking
 */
interface ExecuteRowParams extends DetailExecuteResponse {
  // Projection-specific fields for Redis storage
  tenantId: string;
  version: number;
  updatedAt: Date;
  deletedAt?: Date | null;
  lastStreamRevision?: string | null;
}

/**
 * Execute Projector using Redis-based Shared Projection Infrastructure
 *
 * Leverages CatchUpRunner for event subscription and processing
 * Uses RedisCheckpointStore for distributed checkpoint management
 * Implements projection function pattern for event handling with Redis backend
 *
 * Redis Data Structure (managed by ExecuteProjectionKeys domain value object):
 * - Execute Hash: `execute:projection:{tenantId}:id` - stores all execute fields
 * - Tenant Index: `execute:index:by_tenant:{tenantId}` - sorted set by updated timestamp
 *
 * Key Features:
 * - Uses shared CatchUpRunner for subscription management
 * - Redis-based checkpoint storage for scalability
 * - Redis pipelines for atomic multi-operation transactions
 * - Version-based optimistic concurrency control using Lua scripts
 * - Automatic indexing for efficient querying
 * - Soft delete with TTL for audit purposes
 * - Comprehensive logging and monitoring
 */
@Injectable()
export class ExecuteProjector
  extends BaseProjector
  implements OnModuleInit, OnModuleDestroy
{
  private readonly metricsCollector = new CacheMetricsCollector();

  // ✅ Executeion-ready shared utilities
  private cacheOptimization!: CacheOptimizationUtils;
  private pipelineBuilder!: RedisPipelineBuilder;

  constructor(
    @Inject(APP_LOGGER) baseLogger: Logger,
    @Inject(CLOCK) private readonly clock: Clock,
    @Inject(SLACK_EXECUTE_DI_TOKENS.CATCHUP_RUNNER)
    private readonly catchUpRunner: CatchUpRunner,
    @Inject(CHECKPOINT_STORE) checkpointStore: CheckpointStore,
    @Inject(SLACK_EXECUTE_DI_TOKENS.IO_REDIS)
    private readonly redis: Redis,
    @Inject(SLACK_EXECUTE_DI_TOKENS.CACHE_SERVICE)
    private readonly cache: CacheService,
  ) {
    super(
      ExecuteProjectionKeys.PROJECTOR_NAME,
      ExecuteProjectionKeys.SUBSCRIPTION_GROUP,
      baseLogger,
      checkpointStore,
    );

    // ✅ Initialize shared utilities for executeion-ready operations
    this.cacheOptimization = new CacheOptimizationUtils();
    this.pipelineBuilder = new RedisPipelineBuilder();

    Log.info(
      this.logger,
      'ExecuteProjector initialized with executeion-ready shared utilities',
      {
        method: 'constructor',
        subscriptionGroup: this.subscriptionGroup,
        redisStatus: this.redis.status,
        sharedUtilities: true,
        clusterSafe: true,
        evalshaCaching: true,
      },
    );
  }

  /**
   * Start the projector using CatchUpRunner with executeion-ready utilities
   */
  onModuleInit(): void {
    Log.info(this.logger, 'Starting Execute Projector with CatchUpRunner', {
      method: 'onModuleInit',
      subscriptionGroup: this.subscriptionGroup,
    });

    try {
      // ✅ Register EVALSHA scripts for optimization
      registerRedisScripts(this.redis);
      Log.info(this.logger, 'EVALSHA scripts registered successfully', {
        method: 'onModuleInit',
        feature: 'evalsha-optimization',
      });
      const runOptions: RunOptions = {
        prefixes: [ExecuteProjectionKeys.getEventStoreStreamPrefix()],
        batchSize: 100,
        stopOnCaughtUp: false,
        maxRetries: 3,
        retryDelayMs: 1000,
        checkpointBatchSize: 10,
      };

      // Start the projection in the background without blocking module initialization
      this.catchUpRunner
        .runSafe(
          this.subscriptionGroup,
          this.projectEvent.bind(this) as (
            event: ProjectionEvent,
          ) => Promise<void>,
          runOptions,
        )
        .then((result) => {
          if (!result.ok) {
            this.updateHealthStatusOnError(
              result.error.detail || 'Unknown error',
            );
            Log.error(this.logger, 'Projection failed to start', {
              method: 'onModuleInit',
              error: result.error.detail || 'Unknown error',
            });
          } else {
            Log.info(this.logger, 'Projection completed successfully', {
              method: 'onModuleInit',
              status: 'completed',
            });
          }
        })
        .catch((error) => {
          const e = error as Error;
          this.updateHealthStatusOnError(e.message);
          Log.error(this.logger, 'Projection failed with exception', {
            method: 'onModuleInit',
            error: e.message,
            stack: e.stack,
          });
        });

      this.setRunning(true);
      this.updateHealthStatusOnSuccess();

      Log.info(this.logger, 'Execute Projector started successfully', {
        method: 'onModuleInit',
        status: 'running',
      });
    } catch (error) {
      const e = error as Error;
      this.updateHealthStatusOnError(e.message);

      Log.error(this.logger, 'Failed to start Execute Projector', {
        method: 'onModuleInit',
        error: e.message,
        stack: e.stack,
      });
      throw error;
    }
  }

  /**
   * Stop the projector using CatchUpRunner shutdown
   */
  onModuleDestroy(): void {
    Log.info(this.logger, 'Stopping Execute Projector', {
      method: 'onModuleDestroy',
      subscriptionGroup: this.subscriptionGroup,
    });

    try {
      this.catchUpRunner.stop(this.subscriptionGroup);
      this.setRunning(false);

      Log.info(this.logger, 'Execute Projector stopped successfully', {
        method: 'onModuleDestroy',
        status: 'stopped',
      });
    } catch (error) {
      const e = error as Error;
      Log.error(this.logger, 'Error stopping Execute Projector', {
        method: 'onModuleDestroy',
        error: e.message,
        stack: e.stack,
      });
    }
  }

  /**
   * Project individual event using executeion-ready EventPipelineProcessor
   * with observable outcomes, SET NX EX optimization, and cluster-safe operations
   */
  private async projectEvent(
    event: ProjectionEvent,
  ): Promise<ProjectionOutcome> {
    const tenant = this.extractTenant(event);

    try {
      // ✅ Extract execute parameters using existing utility
      const params = this.extractExecuteParams(event, 'project');

      // ✅ Apply version hint deduplication first (executeion-ready SET NX EX)
      const alreadyProcessed = await CacheOptimizationUtils.checkVersionHint(
        this.redis,
        tenant,
        'execute',
        params.id,
        params.version,
      );

      if (alreadyProcessed) {
        this.logger.debug(
          'Execute already processed - using version hint optimization for ' +
            params.id +
            ' version ' +
            params.version,
        );
        const outcome = ProjectionOutcome.SKIPPED_HINT;
        this.logProjectionOutcome(outcome, event, tenant);
        return outcome;
      }

      // ✅ Build field pairs using shared utility (convert to generic Record)
      const fieldPairs = RedisPipelineBuilder.buildFieldPairs(
        params as unknown as Record<string, unknown>,
      );

      // ✅ Generate cluster-safe keys using centralized ExecuteProjectionKeys
      const entityKey = ExecuteProjectionKeys.getRedisExecuteKey(
        tenant,
        params.id,
      );
      const indexKey = ExecuteProjectionKeys.getRedisTenantIndexKey(tenant);

      // ✅ Validate hash-tag consistency for cluster safety
      RedisClusterUtils.validateHashTagConsistency(entityKey, indexKey);

      // ✅ Create pipeline for atomic operations
      const pipeline = this.redis.pipeline();

      // ✅ Route to soft delete or upsert based on deletion state
      if (params.deletedAt) {
        // Use shared Redis pipeline builder for cluster-safe soft delete
        RedisPipelineBuilder.executeSoftDelete(
          pipeline,
          entityKey,
          indexKey,
          params.id,
          params.deletedAt,
        );

        // ✅ Record soft delete operation (metrics collected by base projector)
      } else {
        // Use shared Redis pipeline builder for cluster-safe upsert
        RedisPipelineBuilder.executeUpsert(
          pipeline,
          entityKey,
          indexKey,
          params.id,
          params.version,
          params.updatedAt,
          fieldPairs,
        );

        // ✅ Record upsert operation (metrics collected by base projector)
      }

      // ✅ Execute pipeline and handle results
      const results = await pipeline.exec();

      // ✅ Check if operations succeeded (non-null results indicate success)
      const operationSucceeded = results && results.every(([error]) => !error);
      const outcome = operationSucceeded
        ? ProjectionOutcome.APPLIED
        : ProjectionOutcome.STALE_OCC;

      // ✅ Update cache hint to prevent reprocessing (race-free SET EX)
      await CacheOptimizationUtils.updateVersionHint(
        this.redis,
        tenant,
        'execute',
        params.id,
        params.version,
      );

      // ✅ Log observable outcomes for SLO monitoring
      this.logProjectionOutcome(outcome, event, tenant);

      return outcome;
    } catch (error) {
      const e = error as Error;
      this.updateHealthStatusOnError(e.message);

      Log.error(this.logger, 'Failed to project event with shared pipeline', {
        method: 'projectEvent',
        eventType: event.type,
        streamId: event.streamId,
        revision: event.revision,
        tenant,
        error: e.message,
        stack: e.stack,
      });

      throw new Error(
        withContext(ExecuteProjectorErrors.DATABASE_OPERATION_FAILED, {
          eventType: event.type,
          streamId: event.streamId,
          originalError: e.message,
        }).detail,
        { cause: e },
      );
    }
  }

  /**
   * Log projection outcomes for SLO monitoring and incident analysis
   */
  private logProjectionOutcome(
    outcome: ProjectionOutcome,
    event: ProjectionEvent,
    tenant: string,
  ): void {
    const outcomeLabels = {
      [ProjectionOutcome.APPLIED]: 'applied',
      [ProjectionOutcome.STALE_OCC]: 'stale_occ',
      [ProjectionOutcome.SKIPPED_DEDUP]: 'skipped_dedup',
      [ProjectionOutcome.SKIPPED_HINT]: 'skipped_hint',
      [ProjectionOutcome.UNKNOWN]: 'unknown',
    };

    const outcomeLabel = outcomeLabels[outcome] || 'unknown';
    const level = outcome === ProjectionOutcome.APPLIED ? 'debug' : 'info';

    Log[level](this.logger, `Event projection outcome: ${outcomeLabel}`, {
      method: 'logProjectionOutcome',
      outcome,
      outcomeLabel,
      eventType: event.type,
      streamId: event.streamId,
      revision: event.revision,
      tenant,
      metrics: this.metricsCollector.getMetrics(),
    });
  }

  /**
   * Extract tenant ID from event using shared utility
   */
  private extractTenant(event: ProjectionEvent): string {
    return TenantExtractor.extractTenant(event);
  }

  /**
   * Generate cluster-safe Redis keys with hash-tags for locality
   */
  private generateClusterSafeKeys(params: ExecuteRowParams): {
    entityKey: string;
    indexKey: string;
  } {
    // ✅ Hash-tags ensure both keys route to same Redis Cluster slot
    const entityKey = 'execute:{' + params.tenantId + '}:' + params.id;
    const indexKey = 'execute:index:{' + params.tenantId + '}';

    Log.debug(this.logger, 'Generated cluster-safe keys with hash-tags', {
      method: 'generateClusterSafeKeys',
      entityKey,
      indexKey,
      tenant: params.tenantId,
      id: params.id,
    });

    return { entityKey, indexKey };
  }

  /**
   * Extract execute parameters from event data using ExecuteFieldValidatorUtil
   *
   * Uses ExecuteFieldValidatorUtil to create validated DetailExecuteResponse for consistent
   * validation across repository and projector, and TenantExtractor for reliable tenant identification.
   */
  private extractExecuteParams(
    event: ProjectionEvent,
    operation: string,
  ): ExecuteRowParams {
    try {
      const eventData = event.data as Record<string, any>;

      // Extract tenant using shared utility
      const tenantId = TenantExtractor.extractTenant(event);

      // Use ExecuteFieldValidatorUtil to create validated execute snapshot
      const executeSnapshot =
        ExecuteFieldValidatorUtil.createExecuteSnapshotFromEventData(eventData);

      // Override envelope fields with actual event envelope data
      // The version, createdAt, updatedAt should come from event envelope, not payload
      const eventTimestamp =
        event.metadata?.occurredAt instanceof Date
          ? event.metadata.occurredAt
          : new Date();

      const eventEnvelope = {
        version: event.revision, // Use event revision as version
        createdAt: eventTimestamp, // Use event timestamp
        updatedAt: eventTimestamp, // Use event timestamp
      };

      // Add projector-specific fields for Redis storage
      return {
        ...executeSnapshot,
        ...eventEnvelope, // Override with correct envelope data
        tenantId,
        deletedAt: null, // Projector handles soft deletes
        lastStreamRevision: event.revision.toString(),
      };
    } catch (error) {
      const e = error as Error;
      throw new Error(
        withContext(ExecuteProjectorErrors.INVALID_EVENT_DATA, {
          eventType: event.type,
          streamId: event.streamId,
          operation,
          originalError: e.message,
        }).detail,
      );
    }
  }
}
